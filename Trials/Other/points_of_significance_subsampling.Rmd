---
title: "Points of Significance: The Class Imbalance Problem"
author:
  - name: "Fadel M. Megahed ^[Email: fmegahed@miamioh.edu | Phone: +1-513-529-4185 | Website: <a href=\"https://miamioh.edu/fsb/directory/?up=/directory/megahefm\">Miami University Official</a>]"
    affiliation: Farmer School of Business, Miami University
bibliography: subsampling.bib
csl: apa.csl
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    number_sections: TRUE
    theme: simplex
    paged_df: TRUE
    code_folding: show
    code_download: TRUE
includes:
  in_header: structure.tex
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      cache = TRUE,
                      progress = FALSE, 
                      verbose = FALSE,
                      dpi = 600,
                      dev = c('png', 'tiff'),
                      out.width = '100%')
options(qwraps2_markup = "markdown")

library(ggplot2); theme_set(theme_bw(base_size = 8, base_family = "Arial"))
if(require(lemon) == FALSE) install.packages("lemon"); library(lemon)
knit_print.data.frame <- lemon_print
```

# R Setup and Required Packages
In this project, the open-source R programming language [@R2021] is used to model the progression in the COVID-19 pandemic in different U.S. counties. R is maintained by an international team of developers who make the language available at [The Comprehensive R Archive Network](https://cran.r-project.org/). Readers interested in reusing our code and reproducing our results should have R installed locally on their machines. R can be installed on a number of different operating systems (see [Windows](https://cran.r-project.org/bin/windows/), [Mac](https://cran.r-project.org/bin/macosx/), and [Linux](https://cran.r-project.org/bin/linux/) for the installation instructions for these systems). We also recommend using the RStudio interface for R. The reader can [download RStudio](http://www.rstudio.com/ide) for free by following the instructions at the link. For non-R users, we recommend the [Hands-on Programming with R](https://rstudio-education.github.io/hopr/packages.html) for a brief overview of the software's functionality. Hereafter, we assume that the reader has an introductory understanding of the R programming language.

In the code chunk below, we load the packages used to support our analysis. Additionally, we source a `custom_functions.R` file that contains several functions that we will utilize in our analysis. Note that the code of this and any of the code chunks can be hidden by clicking on the 'Hide' button to facilitate the navigation. **The reader can hide all code and/or download the Rmd file associated with this document by clicking on the Code button on the top right corner of this document.** 

```{r packages, cache=FALSE}
if(require(pacman)==FALSE) install.packages("pacman") # Install pacman (if not already installed)

pacman::p_load(tidyverse, magrittr, tidymodels, themis, janitor, # typical packages used in data science
               DT, pander, knitr, # for formatting and nicely printed outputs
               rvest, # for getting some datasets
               scales, RColorBrewer, DataExplorer, plotly, ggsci, # for plots
               caret, caTools, MASS, nnet, rpart, ranger, # for ML models
               conflicted) # for managing conflicts in functions with same names

# Handling conflicting function names from packages
conflict_prefer('combine', 'dplyr') # Preferring dplyr::combine over any other package
conflict_prefer('select', "dplyr") #Preferring dplyr::select over any other package
conflict_prefer("summarize", "dplyr") # similar to above but with dplyr::summarize
conflict_prefer("filter", "dplyr") # Preferring filter from dplyr
conflict_prefer("step_downsample", "themis")
conflict_prefer("step_upsample", "themis")
conflict_prefer("step_smote", "themis")
conflict_prefer("sensitivity", "yardstick")
conflict_prefer("specificity", "yardstick")
conflict_prefer("precision", "yardstick")
conflict_prefer("recall", "yardstick")
conflict_prefer("f_meas", "yardstick")

set.seed(2021) # to assist with reproducibility
sInfo = sessionInfo() # saving all the packages/functions & session Info

source("custom_functions.R")
```

---

# Extracting and Transforming the Datasets
In this code chunk, we will extract the **five** two-class imbalanced datasets from the [KEEL Repository](https://sci2s.ugr.es/keel/imbalanced.php?order=ins#subA). The output from this step is a data.frame containing:   

  (a) *dataset*, which captures the name of the dataset,    
  (b) *imbalance_ratio*, which captures the ratio of the $\frac{\text{majority class}}{\text{minority class}}$, i.e., $\frac{\text{negative class}}{\text{positive class}}$,   
  (c) *data*, which captures the entire data for each dataset,  
  (d) *predictors*, which captures the names and values of all the independent variables for each dataset, and   
  (e) *response*, which captures the values of the response variable for each dataset.   
  
Note that the resulting data.frame contains a five rows, corresponding to the total number of datasets, and uses the list column structure that facilitates the utilization of the vectorized `purrr::map()` functions within `dplyr::mutate()`.    
```{r extractData, render = lemon_print, results='hold'}
# Extracting the imbalanced datasets from the KEEL Repository ------------------------------------------------------

# We selected five different datasets from the KEEL site such that they have the following imbalanced ratios
# ecoli1 (IR: 3.36), yeast3 (IR: 8.1), yeast-1-4-5-8_vs_7 (IR: 22.1), yeast6 (IR 41.4), and abalone19 (IR: 129.44)


# * * The URL for each dataset -------------------------------------------------------------------------------------
base_URL = 'https://sci2s.ugr.es/keel/keel-dataset/datasets/imbalanced/'
dataSetLinks = c('imb_IRlowerThan9/ecoli1.zip', 'imb_IRlowerThan9/yeast3.zip', 
                 'imb_IRhigherThan9p1/yeast-1-4-5-8_vs_7.zip', 'imb_IRhigherThan9p1/yeast6.zip',
                 'imb_IRhigherThan9p1/abalone19.zip')


datasetNames = c('ecoli1', 'yeast3', 'yeast-1-4-5-8_vs_7', 'yeast6', 'abalone19')
number_of_attributes = c(7, 8, 8, 8, 8)

kDataFullLinks = paste0(base_URL, dataSetLinks)


# * * The Metatable for Each Dataset -------------------------------------------------------------------------------
metaTable = data.frame(name = datasetNames, 
                         number_of_attributes = c(7, 8, 8, 8, 8),
                         number_of_observations = c(336, 1484, 693, 1484, 4174),
                         imbalance_ratio = c( 3.36, 8.1, 22.1, 41.4, 129.44))

metaTable

# * * Creating a data.frame of the datasets with the following columns:
### (dataset, imbalance_ratio, data, predictors and response)
datasets = keelData(kDataFullLinks, datasetNames, numAttributes,
                    dest = here::here("Data/imbalancedDatasets")) %>% 
  enframe(name = "dataset", value = "data") %>% 
  mutate(predictors = map(.x = data, .f = select, -c(contains("Class" ))),
           response = map(.x = data, .f = select, contains("Class")) ) %>% 
  mutate(predictors = map(.x = predictors, .f =tibble),
           response = map(.x = response, .f = extract2, 1)) %>% 
  left_join(metaTable,
            by = c("dataset" = "name") , keep = FALSE) %>% 
  select(dataset, imbalance_ratio, data, predictors, response)

glimpse(datasets)
  
saveRDS(datasets, "Data/results/datasets.rds")
```

---

# Machine Learning Models
In the code chunk below, we define four subsampling scenarios and five machine learning models that will be examined in our experiment. Note that the `mlFuncFact()` is defined in our `custom_functions.R` file, which we sourced in Section 1 of this document.
```{r functions}

dataset = readRDS("Data/results/datasets.rds")

subsampling = c('none', 'down', 'up', 'smote')

log_spec = logistic_reg() %>% set_engine("glm", num.threads=6, seed = 2021) %>%
  set_mode("classification")

cart_spec = decision_tree() %>% set_engine("rpart", num.threads=6, seed = 2021) %>%
  set_mode("classification")

nnet_spec = mlp() %>% set_engine("keras", num.threads=6, seed = 2021) %>% 
  set_mode("classification")

rf_spec = rand_forest() %>% set_engine("ranger", num.threads=6, seed = 2021) %>% 
  set_mode("classification")

svm_spec = svm_rbf() %>%  set_engine("kernlab", num.threads=6, seed = 2021) %>% 
  set_mode("classification") 

model_df = list(
  logReg = log_spec,
  cart = cart_spec,
  nnet = nnet_spec,
  rf = rf_spec,
  svm = svm_spec
  ) %>% enframe(name = 'model', value = 'model_func')

```

---

# Experimentation

## Running the Experiment for the ecoli1 Dataset
```{r experimentROC}
# Reading the ecoli1 dataset, making variable names lower case and setting 'positive' as first factor level -----
ecoli1 = datasets$data[[1]] %>% 
  clean_names() %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(class = relevel(class, ref = 'positive')) 


# Splitting the data into training/validation and testing -----
set.seed(2021)
ecoli1_split = initial_split(ecoli1, prop = 0.8, strata = class)

ecoli1_train = training(ecoli1_split)
ecoli1_folds = vfold_cv(ecoli1_train, v = 10, strata = class)

ecoli1_test = testing(ecoli1_split)

base_recipe = recipe(class ~ ., data = ecoli1_train) %>% 
  step_dummy(all_nominal_predictors()) %>% # create dummy variables from factor columns 
  step_zv(all_predictors()) %>% # remove any columns with a single unique value
  step_normalize(all_numeric_predictors()) # center and scale all numeric predictors

down_sample = base_recipe %>% step_downsample(class)
up_sample = base_recipe %>% step_upsample(class)
smote_sample = base_recipe %>% step_smote(class)


# Training the machine learning models with different recipes ----
# Model metrics
metrics = metric_set(f_meas, accuracy, sensitivity, specificity, pr_auc, precision, recall, roc_auc)

doParallel::registerDoParallel()
rs = workflow() %>%
  add_recipe(down_sample) %>% 
  add_model(rf_spec) %>% 
  fit_resamples(
    resamples = ecoli1_folds,
    metrics = metrics,
    control = control_resamples(save_pred = T)
  )

collect_metrics(rs)

```



---



---


# Conclusions


---

# References {-}
